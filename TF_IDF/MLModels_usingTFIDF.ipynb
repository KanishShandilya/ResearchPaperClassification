{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309fbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456e0a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(\"../dataset/X_train.csv\")\n",
    "X_test=pd.read_csv(\"../dataset/X_test.csv\")\n",
    "y_train=pd.read_csv(\"../dataset/y_train.csv\")\n",
    "y_test=pd.read_csv(\"../dataset/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a4d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title=X_train['TITLE']\n",
    "X_train_abstract=X_train['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4a5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_title=TfidfVectorizer()\n",
    "title_feature=tf_idf_title.fit_transform(X_train_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08dcf944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16777, 12505)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(title_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68bb296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_feature_test=tf_idf_title.transform(X_test['TITLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d97a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_abstract=TfidfVectorizer(ngram_range=(1,3),min_df=3)\n",
    "abstract_feature=tf_idf_abstract.fit_transform(X_train_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf777f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16777, 115133)\n"
     ]
    }
   ],
   "source": [
    "print(abstract_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a60762",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_feature_test=tf_idf_abstract.transform(X_test['ABSTRACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5193ef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4195, 115133)\n",
      "(4195, 12505)\n"
     ]
    }
   ],
   "source": [
    "print(abstract_feature_test.shape)\n",
    "print(title_feature_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb30369",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final=hstack((title_feature,abstract_feature))\n",
    "X_test_final=hstack((title_feature_test,abstract_feature_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "487ab20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16777, 127638)\n",
      "(4195, 127638)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ba0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e57bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f779bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5969010727056019\n",
      "Hamming loss  0.08943186332936034\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8885, Recall: 0.6536, F1-measure: 0.7532\n",
      "Macro-average quality numbers\n",
      "Precision: 0.6059, Recall: 0.4318, F1-measure: 0.4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanis\\anaconda3\\envs\\toxic_comment_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classifier = OneVsRestClassifier(MultinomialNB())\n",
    "classifier.fit(X_train_final, y_train)\n",
    "predictions = classifier.predict (X_test_final)\n",
    "\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='micro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='micro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='macro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='macro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b2940e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6123957091775923\n",
      "Hamming loss  0.08537941994437823\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7838, Recall: 0.8161, F1-measure: 0.7996\n",
      "Macro-average quality numbers\n",
      "Precision: 0.5261, Recall: 0.5603, F1-measure: 0.5405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanis\\anaconda3\\envs\\toxic_comment_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = OneVsRestClassifier(BernoulliNB())\n",
    "nb_classifier.fit(X_train_final, y_train)\n",
    "predictions = nb_classifier.predict (X_test_final)\n",
    "\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='micro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='micro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='macro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='macro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8426195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.634326579261025\n",
      "Hamming loss  0.07926102502979737\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7787, Recall: 0.8666, F1-measure: 0.8203\n",
      "Macro-average quality numbers\n",
      "Precision: 0.7025, Recall: 0.8027, F1-measure: 0.7480\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = OneVsRestClassifier(LogisticRegression(max_iter=500,class_weight='balanced'))\n",
    "lr_classifier.fit(X_train_final, y_train)\n",
    "predictions = lr_classifier.predict (X_test_final)\n",
    "\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='micro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='micro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='macro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='macro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b8dc1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6474374255065555\n",
      "Hamming loss  0.07767183154549066\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8091, Recall: 0.8219, F1-measure: 0.8154\n",
      "Macro-average quality numbers\n",
      "Precision: 0.7674, Recall: 0.7224, F1-measure: 0.7403\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = OneVsRestClassifier(LinearSVC(class_weight='balanced'))\n",
    "svm_classifier.fit(X_train_final, y_train)\n",
    "predictions = svm_classifier.predict (X_test_final)\n",
    "\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='micro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='micro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='micro')\n",
    " \n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = metrics.precision_score(y_test, predictions, average='macro')\n",
    "recall = metrics.recall_score(y_test, predictions, average='macro')\n",
    "f1 = metrics.f1_score(y_test, predictions, average='macro')\n",
    " \n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34bdd16",
   "metadata": {},
   "source": [
    "## Best model is Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9c84a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/tf-idf_svm.pkl', 'wb') as fid:\n",
    "    pickle.dump(svm_classifier, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c9a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
